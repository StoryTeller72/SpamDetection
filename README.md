# SpamDetection
В рамках данного проекта решалась задача классификации электронных писем на спам и не спам с помощью классических алгоритмов машинного обучения. 

[Датасет](https://www.kaggle.com/datasets/purusinghvi/email-spam-classification-dataset/data) был взят с сайта Kaggle. 

## Цели.
- провести предобработку текстов (удаление символов пунктуации, лематизация, удаление стоп слов)
- реализовать самостоятельно наивный байесовский классификатор
- изучить разные способы векторизациия текста (BagOfWords, TF-IDF)
- обучить наивный байесовский классификатор из библиотеки sklearn
- обучить SVM из библиотеки sklearn
- сравнить результаты 

## Результаты
В качестве основной метрики для оценки качества моделей будем использовать precision, потому что мы хотим избегать ошибок первого рода (ложноположительных прогнозов). В данной задаче гораздо хуже если модель определит в спам важное письмо и пользователь его не увидит, чем если модель иногда будет пропускать спам рассылки (ошибка второго рода). Для полноты оценки также рассмотрим recall, F1.

|меодель/метрика         | precision| recall| F1   |
|------------------------|----------|-------|------|
|self-written Naive Bayes + BOF|  0.592   |0.725  |0.652 |
|sklearn Naive Bayes + BOF     |  0.987   |0.96   |0.974 |
| sklearn SVM  + TF-IDF        | 0.987    |0.960  |0.974 |   

## Выводы
Самописный алгоритм показал достаточно хорошие результаты (особенно recall), но библиотечные реализации сильно его превзошли. Данные результаты говорят о том, что при правильной обработке текста классические алгоритмы тоже могут выдавать достойные результаты и их  можно использовать как отправные точки (baseline) в задачах. 


